{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af6cabba-a01d-457c-b118-e0faf4c05c02",
   "metadata": {},
   "source": [
    "# CIFAR10 MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd6db8-246c-489b-b748-2a7095bfe3a1",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks model should perform a lot better in tackling this problem, however I will still try with MLP model and see how much I can do with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cfa57c-f737-4e47-aa48-06e9dbbdfecc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "311d8a45-9943-41e7-a561-b5b9d03ebab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from mltoolkit.utils import dump_keras_model,dump_arrays,dump_sklearn_model,\\\n",
    "                            get_tf_logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca99f48-ad4c-489f-93db-9c6274d821bd",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b9ae3c2-8c2a-4c99-80a1-589e8ea2387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_logdir(name,root=\"C:\\\\Users\\\\pi314\\\\Learning\\\\Data Science\\\\TensorFlow\\\\\"):\n",
    "    '''\n",
    "    Get a new logdir for tensorboard with the current timestamp.\n",
    "    \n",
    "    Parameters:\n",
    "    name: str\n",
    "        The extra name as suffix for the logdir.\n",
    "    '''\n",
    "    timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    if name: name = timestamp+'_'+name\n",
    "    else: name = timestamp\n",
    "    logdir = os.path.join(root,\"Tensorboard\",name)\n",
    "    os.makedirs(logdir,exist_ok=True)\n",
    "    return logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cc3ef118-80ea-4e75-8f5d-e3e436071c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mlp(Input_X,output_y,hidden_layers,neurons,\n",
    "             flatten=False,\n",
    "             hid_activation='relu',\n",
    "             hid_initializer='glorot_uniform',\n",
    "             hid_regularizer=None,\n",
    "             out_activation=None,\n",
    "             batch_norm=False):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Input(shape=Input_X.shape[1:])\n",
    "    ])\n",
    "    if flatten: model.add(keras.layers.Flatten())\n",
    "    if batch_norm: model.add(keras.layers.BatchNormalization())\n",
    "    if not batch_norm:\n",
    "        [model.add(layer) for layer in [\n",
    "            keras.layers.Dense(neurons,\n",
    "                               activation=hid_activation,\n",
    "                               kernel_initializer=hid_initializer,\n",
    "                               kernel_regularizer=hid_regularizer)\n",
    "            for i in range(hidden_layers)\n",
    "        ]]\n",
    "    else:\n",
    "        [[model.add(layer),\n",
    "         model.add(keras.layers.BatchNormalization()),\n",
    "         model.add(keras.layers.Activation(hid_activation))] \n",
    "         for layer in [\n",
    "            keras.layers.Dense(neurons,\n",
    "                               kernel_initializer=hid_initializer,\n",
    "                               kernel_regularizer=hid_regularizer)\n",
    "            for i in range(hidden_layers)\n",
    "        ]]\n",
    "        \n",
    "    \n",
    "    if output_y.dtype == int or output_y.dtype == float:\n",
    "        model.add(keras.layers.Dense(1,activation=None))\n",
    "    else:\n",
    "        model.add(keras.layers.Dense(np.unique(output_y).size,activation=out_activation))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "604a0bd9-b15f-4c27-bb4e-681dd6a07049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dump_keras_model(model,path=\"Trained Models\\\\\",filename=None,\n",
    "                     yhat=None,scores=None,compress=5,save_weights=False,\n",
    "                     weights_precision='half'):\n",
    "    '''\n",
    "    FOR Keras Model ONLY.\n",
    "    Dump the objects passed as arguments into .h5 and .pkl file.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    model: keras model\n",
    "        The keras model to be dumped.\n",
    "    path: str, Default: \"Trained Models\\\\\"\n",
    "        The path to dump the model.\n",
    "    filename:\n",
    "        The filename to be dumped. If None, model default name instance will be\n",
    "        used.\n",
    "    yhat: array, list, dict etc., Default: None\n",
    "        Predicted datasets of the model.\n",
    "    scores: array, list, dict etc., Default: None\n",
    "        Evaluation scores of the model.\n",
    "    compress: int, Default: 5\n",
    "        Compression ratio for yhat and scores only (joblib.dump).\n",
    "    save_weights: bool, Default: False\n",
    "        If True, model's weights will be saved as well in .CSV format.\n",
    "    weights_precision: str | {'half','full'}, Default: 'half'\n",
    "        If half, floats will be stored at a smaller precision and comsumes\n",
    "        lesser space. If full, floats will be stored at the highest precision.\n",
    "    '''\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except:\n",
    "        pass\n",
    "    timestamp = datetime.today().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    # Dump keras model\n",
    "    if not filename: filename = model.name\n",
    "    model.save(filepath=path+timestamp+'_'+filename)\n",
    "    if save_weights:\n",
    "        os.makedirs(path+timestamp+'_'+filename+'_weights')\n",
    "        for weight in model.weights:\n",
    "            name = weight.name[:weight.name.find(':')].replace('/','_')\n",
    "            if weights_precision == 'full':\n",
    "                np.savetxt(path+timestamp+'_'+filename+'_weights'+'\\\\'+f'{name}_weights.csv',\n",
    "                           weight.numpy(),delimiter=',',fmt='%.18f',encoding='utf-8')\n",
    "            elif weights_precision == 'half':\n",
    "                pd.DataFrame(weight.numpy()).to_csv(path+timestamp+'_'+filename+'_weights'+'\\\\'+f'{name}_weights.csv',\n",
    "                                         index=False)\n",
    "            else:\n",
    "                raise ValueError(\"Only 'half' or 'full' are allowed for 'weights_precision'\")\n",
    "            \n",
    "    # Dump yhat\n",
    "    path2 = path+timestamp+'_'+filename+'\\\\'\n",
    "    if yhat is not None:\n",
    "        joblib.dump(yhat,path2+timestamp+'_'+filename+\"_yhat.pkl\",compress=compress)\n",
    "    # Dump scores\n",
    "    if scores is not None:\n",
    "        joblib.dump(scores,path2+timestamp+'_'+filename+\"_scores.pkl\",compress=compress)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a500d98b-c8f3-4dda-922a-d09fbf28ce95",
   "metadata": {},
   "source": [
    "## Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ee6ba9-83ec-485f-884a-e00dc7d683c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 700), (10000, 700), (50000,), (10000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trans = joblib.load(\"Datasets\\\\X_train_trans.pkl\")\n",
    "X_test_trans = joblib.load(\"Datasets\\\\X_test_trans.pkl\")\n",
    "y_train_raw = joblib.load(\"Datasets\\\\Raw Data\\\\y_train_raw.pkl\")\n",
    "y_test_raw = joblib.load(\"Datasets\\\\Raw Data\\\\y_test_raw.pkl\")\n",
    "\n",
    "X_train_trans.shape,X_test_trans.shape,y_train_raw.shape,y_test_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa98e1-6046-4948-a0d3-9e6b42e82910",
   "metadata": {},
   "source": [
    "Note that the X_train and X_test are both PCA transformed with 700 components to reduce the dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e10f38-1aa5-4485-bd36-a82606487a6c",
   "metadata": {},
   "source": [
    "## Splitting the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d53c8ec6-87b3-4a3d-9f6d-ba8a0fff6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_valid,y_train,y_valid = train_test_split(X_train_trans,y_train_raw,test_size=0.1,stratify=y_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f4029d-c504-42c9-b99c-4ba47129358f",
   "metadata": {},
   "source": [
    "## MLP (20 x 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230982fd-171e-4742-94e2-ad54b33d1682",
   "metadata": {},
   "source": [
    "mlp_0: Default MLP with 20 hidden layers and 100 neurons each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d1d5aa97-7675-4a67-8159-e0c0091136b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_0 = make_mlp(X_train_trans,y_train,20,100,'elu','he_normal',out_activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c3557e20-a186-4477-ab9b-5ee4970155d9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_105 (Dense)           (None, 100)               70100     \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 263,010\n",
      "Trainable params: 263,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1154554a-3a14-4aeb-a785-0577541ff833",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_0_logdir = get_tf_logdir(\"mlp_0\")\n",
    "mlp_0_tfboard = keras.callbacks.TensorBoard(mlp_0_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ba4027e2-8f44-4557-9b94-0540793b3a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_0_early = keras.callbacks.EarlyStopping(patience=10)\n",
    "mlp_0_opt = keras.optimizers.Nadam(learning_rate=0.001)\n",
    "mlp_0_schedule = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',factor=0.5,patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "195363c4-57dc-4f6c-a907-3650c3d28168",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_0.compile(optimizer=mlp_0_opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1be6b270-1020-4b3a-ab02-17e38de22cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 8s 55ms/step - loss: 2.0199 - accuracy: 0.2841 - val_loss: 1.8525 - val_accuracy: 0.3302 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 1.6700 - accuracy: 0.4026 - val_loss: 1.6546 - val_accuracy: 0.4094 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 1.5344 - accuracy: 0.4538 - val_loss: 1.6637 - val_accuracy: 0.4036 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.4325 - accuracy: 0.4894 - val_loss: 1.5800 - val_accuracy: 0.4506 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.3460 - accuracy: 0.5230 - val_loss: 1.5753 - val_accuracy: 0.4562 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.2797 - accuracy: 0.5466 - val_loss: 1.5832 - val_accuracy: 0.4514 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.2049 - accuracy: 0.5727 - val_loss: 1.5705 - val_accuracy: 0.4582 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.1511 - accuracy: 0.5920 - val_loss: 1.5771 - val_accuracy: 0.4718 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.0833 - accuracy: 0.6157 - val_loss: 1.7137 - val_accuracy: 0.4456 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.0353 - accuracy: 0.6323 - val_loss: 1.6857 - val_accuracy: 0.4544 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.9816 - accuracy: 0.6532 - val_loss: 1.7090 - val_accuracy: 0.4596 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.7957 - accuracy: 0.7208 - val_loss: 1.8198 - val_accuracy: 0.4570 - lr: 5.0000e-04\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.7170 - accuracy: 0.7508 - val_loss: 1.9231 - val_accuracy: 0.4562 - lr: 5.0000e-04\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.6675 - accuracy: 0.7700 - val_loss: 2.0139 - val_accuracy: 0.4528 - lr: 5.0000e-04\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 0.5498 - accuracy: 0.8152 - val_loss: 2.1826 - val_accuracy: 0.4518 - lr: 2.5000e-04\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 0.4946 - accuracy: 0.8370 - val_loss: 2.3031 - val_accuracy: 0.4552 - lr: 2.5000e-04\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.4527 - accuracy: 0.8517 - val_loss: 2.4611 - val_accuracy: 0.4446 - lr: 2.5000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a450dd89d0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_0.fit(X_train,y_train,batch_size=500,epochs=200,\n",
    "          callbacks=[mlp_0_tfboard,mlp_0_early,mlp_0_schedule],\n",
    "          validation_data=[X_valid,y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e9059027-b1ab-4da8-89b9-aa0abbdbd7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 2.4151 - accuracy: 0.4565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4150688648223877, 0.45649999380111694]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_0.evaluate(X_test_trans,y_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4f41dc-2113-406c-9068-bb3f13f39a22",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "92a1c2b2-1378-4f6b-8850-520f60b47580",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_keras_model(mlp_0,filename=\"mlp_0.h5\",save_weights=True,weights_precision='half')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ce7e33-d212-4250-a52e-25a9e2a0c8f4",
   "metadata": {},
   "source": [
    "## MLP (20 x 100, Batch Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b4c39ab3-a5b9-4b8d-9f82-96b3a484d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_1 = make_mlp(X_train_trans,y_train,20,100,'elu','he_normal',out_activation='softmax',batch_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "451e7aeb-ed5e-4c36-b538-552e8bfb4c4d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 700)              2800      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 100)               70100     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 273,810\n",
      "Trainable params: 268,410\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a2dcb56e-766b-4971-8ef1-3a524690690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_1_logdir = get_tf_logdir(\"mlp_1\")\n",
    "mlp_1_tfboard = keras.callbacks.TensorBoard(mlp_1_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ffd76c66-b532-4f7c-a0c7-2b038b78c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_1_early = keras.callbacks.EarlyStopping(patience=10)\n",
    "mlp_1_opt = keras.optimizers.Nadam(learning_rate=0.001)\n",
    "mlp_1_schedule = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',factor=0.5,patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e9884718-f3a7-4ccc-83cf-3015598b79e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_1.compile(optimizer=mlp_1_opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "412521f8-ebcd-4379-8eb0-a2dc2928b6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 21s 137ms/step - loss: 2.2421 - accuracy: 0.1709 - val_loss: 2.4385 - val_accuracy: 0.2186 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 11s 125ms/step - loss: 1.8470 - accuracy: 0.3134 - val_loss: 2.4437 - val_accuracy: 0.2944 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 11s 126ms/step - loss: 1.6470 - accuracy: 0.4008 - val_loss: 2.0181 - val_accuracy: 0.3574 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 11s 125ms/step - loss: 1.5074 - accuracy: 0.4564 - val_loss: 1.8677 - val_accuracy: 0.3924 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 11s 125ms/step - loss: 1.3914 - accuracy: 0.5006 - val_loss: 1.7721 - val_accuracy: 0.4060 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 11s 125ms/step - loss: 1.2894 - accuracy: 0.5410 - val_loss: 1.7670 - val_accuracy: 0.4092 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 12s 128ms/step - loss: 1.2005 - accuracy: 0.5751 - val_loss: 1.7692 - val_accuracy: 0.4116 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 11s 125ms/step - loss: 1.1133 - accuracy: 0.6058 - val_loss: 1.8094 - val_accuracy: 0.4122 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 11s 125ms/step - loss: 1.0397 - accuracy: 0.6317 - val_loss: 1.8737 - val_accuracy: 0.4118 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 11s 128ms/step - loss: 0.9712 - accuracy: 0.6580 - val_loss: 1.9355 - val_accuracy: 0.4126 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 12s 129ms/step - loss: 0.9052 - accuracy: 0.6840 - val_loss: 2.0157 - val_accuracy: 0.4094 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 11s 127ms/step - loss: 0.8417 - accuracy: 0.7045 - val_loss: 2.1028 - val_accuracy: 0.4056 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 11s 124ms/step - loss: 0.7898 - accuracy: 0.7235 - val_loss: 2.1553 - val_accuracy: 0.4124 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 11s 125ms/step - loss: 0.6249 - accuracy: 0.7851 - val_loss: 2.1950 - val_accuracy: 0.4078 - lr: 5.0000e-04\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 11s 126ms/step - loss: 0.5507 - accuracy: 0.8134 - val_loss: 2.3533 - val_accuracy: 0.3992 - lr: 5.0000e-04\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 11s 124ms/step - loss: 0.5106 - accuracy: 0.8264 - val_loss: 2.4956 - val_accuracy: 0.4006 - lr: 5.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a45d201210>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_1.fit(X_train,y_train,batch_size=500,epochs=200,\n",
    "          callbacks=[mlp_1_tfboard,mlp_1_early,mlp_1_schedule],\n",
    "          validation_data=[X_valid,y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d6ab8b-4921-4481-816b-f578a829b549",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b71e3bfe-73e0-4234-8f10-a27bbc372f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_keras_model(mlp_1,filename=\"mlp_1_batch_norm.h5\",save_weights=True,weights_precision='half')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead392a-1b94-4c5d-994e-f8096205b7ab",
   "metadata": {},
   "source": [
    "## MLP (20 x 100, no PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7624e307-6c02-40a6-aac1-80b2b82d2719",
   "metadata": {},
   "source": [
    "I am suspecting the PCA actually make the training worse. Let's try once with the same configuration as mlp_0 but with the raw dataset without PCA transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ef139b94-6d5c-4d65-9404-3a24f033a21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw = joblib.load(\"Datasets\\\\Raw Data\\\\X_train_raw.pkl\")\n",
    "X_test_raw = joblib.load(\"Datasets\\\\Raw Data\\\\X_test_raw.pkl\")\n",
    "X_train_raw.shape,X_test_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b86b4656-530c-4dd6-9d72-caf2b4420ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nopca,X_valid_nopca,y_train_nopca,y_valid_nopca = train_test_split(X_train_raw,y_train_raw,test_size=0.1,stratify=y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f58dd9a8-dc3c-4642-9ae5-58cdb5a0ee08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45000, 32, 32, 3), (5000, 32, 32, 3), (45000,), (5000,))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nopca.shape,X_valid_nopca.shape,y_train_nopca.shape,y_valid_nopca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0c7150c0-8454-4511-8d54-6961da5d1798",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_2 = make_mlp(X_train_raw.copy(),y_train,20,100,True,'elu','he_normal',out_activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "df34cf8d-7680-462a-98b6-b70b38a2197d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 100)               307300    \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "014d3e1e-4a0f-4b7f-a333-3834891cedcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_2_logdir = get_tf_logdir(\"mlp_2\")\n",
    "mlp_2_tfboard = keras.callbacks.TensorBoard(mlp_2_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "77a0832f-3efa-4ea3-a324-7a43f42794db",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_2_early = keras.callbacks.EarlyStopping(patience=10)\n",
    "mlp_2_opt = keras.optimizers.Nadam(learning_rate=0.001)\n",
    "mlp_2_schedule = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2d12f1e4-1d29-49ad-bb30-4017d443ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_2.compile(optimizer=mlp_2_opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bccec7bd-9968-4617-af82-09a6d89381b1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 8s 58ms/step - loss: 22.3890 - accuracy: 0.1074 - val_loss: 4.3517 - val_accuracy: 0.1254 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 2.6688 - accuracy: 0.1602 - val_loss: 2.2837 - val_accuracy: 0.1708 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 2.1512 - accuracy: 0.2044 - val_loss: 2.0148 - val_accuracy: 0.2570 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 2.0460 - accuracy: 0.2420 - val_loss: 2.0690 - val_accuracy: 0.2334 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.9970 - accuracy: 0.2676 - val_loss: 1.9228 - val_accuracy: 0.2958 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.9550 - accuracy: 0.2834 - val_loss: 1.8818 - val_accuracy: 0.3060 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.9354 - accuracy: 0.2969 - val_loss: 1.8587 - val_accuracy: 0.3318 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.8986 - accuracy: 0.3112 - val_loss: 1.8591 - val_accuracy: 0.3178 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.8838 - accuracy: 0.3184 - val_loss: 1.8179 - val_accuracy: 0.3440 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.8678 - accuracy: 0.3243 - val_loss: 1.8268 - val_accuracy: 0.3466 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 1.8469 - accuracy: 0.3289 - val_loss: 1.8941 - val_accuracy: 0.3198 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.8350 - accuracy: 0.3347 - val_loss: 1.7845 - val_accuracy: 0.3592 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.8293 - accuracy: 0.3401 - val_loss: 1.8527 - val_accuracy: 0.3396 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.8081 - accuracy: 0.3453 - val_loss: 1.7498 - val_accuracy: 0.3612 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 1.8074 - accuracy: 0.3439 - val_loss: 1.7597 - val_accuracy: 0.3704 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.7829 - accuracy: 0.3540 - val_loss: 1.7514 - val_accuracy: 0.3678 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 1.7776 - accuracy: 0.3563 - val_loss: 1.7869 - val_accuracy: 0.3596 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 1.6995 - accuracy: 0.3837 - val_loss: 1.6991 - val_accuracy: 0.3902 - lr: 5.0000e-04\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 1.6916 - accuracy: 0.3877 - val_loss: 1.6955 - val_accuracy: 0.3848 - lr: 5.0000e-04\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 1.6845 - accuracy: 0.3907 - val_loss: 1.6964 - val_accuracy: 0.3842 - lr: 5.0000e-04\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.6804 - accuracy: 0.3913 - val_loss: 1.7119 - val_accuracy: 0.3826 - lr: 5.0000e-04\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 1.6794 - accuracy: 0.3935 - val_loss: 1.6931 - val_accuracy: 0.3888 - lr: 5.0000e-04\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 1.6712 - accuracy: 0.3951 - val_loss: 1.6750 - val_accuracy: 0.3894 - lr: 5.0000e-04\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.6694 - accuracy: 0.3973 - val_loss: 1.7072 - val_accuracy: 0.3772 - lr: 5.0000e-04\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.6795 - accuracy: 0.3940 - val_loss: 1.6610 - val_accuracy: 0.4010 - lr: 5.0000e-04\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.6712 - accuracy: 0.3942 - val_loss: 1.6880 - val_accuracy: 0.3948 - lr: 5.0000e-04\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.6707 - accuracy: 0.4006 - val_loss: 1.6670 - val_accuracy: 0.3950 - lr: 5.0000e-04\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.6638 - accuracy: 0.4005 - val_loss: 1.6603 - val_accuracy: 0.4024 - lr: 5.0000e-04\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.6541 - accuracy: 0.4028 - val_loss: 1.7242 - val_accuracy: 0.3698 - lr: 5.0000e-04\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 1.6629 - accuracy: 0.4014 - val_loss: 1.6390 - val_accuracy: 0.4060 - lr: 5.0000e-04\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.6505 - accuracy: 0.4048 - val_loss: 1.6483 - val_accuracy: 0.4014 - lr: 5.0000e-04\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.6475 - accuracy: 0.4034 - val_loss: 1.6718 - val_accuracy: 0.3898 - lr: 5.0000e-04\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.6475 - accuracy: 0.4062 - val_loss: 1.6516 - val_accuracy: 0.4080 - lr: 5.0000e-04\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 1.5798 - accuracy: 0.4299 - val_loss: 1.6372 - val_accuracy: 0.4112 - lr: 2.5000e-04\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.5749 - accuracy: 0.4325 - val_loss: 1.6250 - val_accuracy: 0.4108 - lr: 2.5000e-04\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 1.5755 - accuracy: 0.4309 - val_loss: 1.6293 - val_accuracy: 0.4132 - lr: 2.5000e-04\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.5672 - accuracy: 0.4360 - val_loss: 1.6272 - val_accuracy: 0.4100 - lr: 2.5000e-04\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 1.5682 - accuracy: 0.4347 - val_loss: 1.6260 - val_accuracy: 0.4174 - lr: 2.5000e-04\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.5465 - accuracy: 0.4436 - val_loss: 1.6157 - val_accuracy: 0.4140 - lr: 1.2500e-04\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.5430 - accuracy: 0.4446 - val_loss: 1.6112 - val_accuracy: 0.4140 - lr: 1.2500e-04\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.5394 - accuracy: 0.4461 - val_loss: 1.6117 - val_accuracy: 0.4162 - lr: 1.2500e-04\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 1.5393 - accuracy: 0.4463 - val_loss: 1.6115 - val_accuracy: 0.4200 - lr: 1.2500e-04\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.5371 - accuracy: 0.4455 - val_loss: 1.6076 - val_accuracy: 0.4206 - lr: 1.2500e-04\n",
      "Epoch 44/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.5351 - accuracy: 0.4472 - val_loss: 1.6097 - val_accuracy: 0.4154 - lr: 1.2500e-04\n",
      "Epoch 45/200\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 1.5317 - accuracy: 0.4488 - val_loss: 1.6083 - val_accuracy: 0.4160 - lr: 1.2500e-04\n",
      "Epoch 46/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.5312 - accuracy: 0.4489 - val_loss: 1.6109 - val_accuracy: 0.4188 - lr: 1.2500e-04\n",
      "Epoch 47/200\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 1.5183 - accuracy: 0.4550 - val_loss: 1.6048 - val_accuracy: 0.4184 - lr: 6.2500e-05\n",
      "Epoch 48/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.5172 - accuracy: 0.4552 - val_loss: 1.6039 - val_accuracy: 0.4192 - lr: 6.2500e-05\n",
      "Epoch 49/200\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 1.5166 - accuracy: 0.4558 - val_loss: 1.6045 - val_accuracy: 0.4186 - lr: 6.2500e-05\n",
      "Epoch 50/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.5146 - accuracy: 0.4566 - val_loss: 1.6050 - val_accuracy: 0.4236 - lr: 6.2500e-05\n",
      "Epoch 51/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.5132 - accuracy: 0.4576 - val_loss: 1.6016 - val_accuracy: 0.4258 - lr: 6.2500e-05\n",
      "Epoch 52/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.5117 - accuracy: 0.4579 - val_loss: 1.6025 - val_accuracy: 0.4228 - lr: 6.2500e-05\n",
      "Epoch 53/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.5102 - accuracy: 0.4584 - val_loss: 1.6033 - val_accuracy: 0.4246 - lr: 6.2500e-05\n",
      "Epoch 54/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.5099 - accuracy: 0.4579 - val_loss: 1.5989 - val_accuracy: 0.4196 - lr: 6.2500e-05\n",
      "Epoch 55/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.5068 - accuracy: 0.4587 - val_loss: 1.6023 - val_accuracy: 0.4240 - lr: 6.2500e-05\n",
      "Epoch 56/200\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 1.5070 - accuracy: 0.4589 - val_loss: 1.6048 - val_accuracy: 0.4212 - lr: 6.2500e-05\n",
      "Epoch 57/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.5048 - accuracy: 0.4584 - val_loss: 1.6013 - val_accuracy: 0.4230 - lr: 6.2500e-05\n",
      "Epoch 58/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.4972 - accuracy: 0.4624 - val_loss: 1.5997 - val_accuracy: 0.4252 - lr: 3.1250e-05\n",
      "Epoch 59/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.4959 - accuracy: 0.4637 - val_loss: 1.6009 - val_accuracy: 0.4246 - lr: 3.1250e-05\n",
      "Epoch 60/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.4949 - accuracy: 0.4645 - val_loss: 1.5993 - val_accuracy: 0.4216 - lr: 3.1250e-05\n",
      "Epoch 61/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.4917 - accuracy: 0.4650 - val_loss: 1.5989 - val_accuracy: 0.4240 - lr: 1.5625e-05\n",
      "Epoch 62/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.4909 - accuracy: 0.4658 - val_loss: 1.5975 - val_accuracy: 0.4246 - lr: 1.5625e-05\n",
      "Epoch 63/200\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 1.4904 - accuracy: 0.4671 - val_loss: 1.5969 - val_accuracy: 0.4252 - lr: 1.5625e-05\n",
      "Epoch 64/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.4898 - accuracy: 0.4653 - val_loss: 1.5976 - val_accuracy: 0.4252 - lr: 1.5625e-05\n",
      "Epoch 65/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.4895 - accuracy: 0.4669 - val_loss: 1.5986 - val_accuracy: 0.4262 - lr: 1.5625e-05\n",
      "Epoch 66/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.4892 - accuracy: 0.4659 - val_loss: 1.5982 - val_accuracy: 0.4280 - lr: 1.5625e-05\n",
      "Epoch 67/200\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 1.4865 - accuracy: 0.4666 - val_loss: 1.5964 - val_accuracy: 0.4244 - lr: 7.8125e-06\n",
      "Epoch 68/200\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 1.4861 - accuracy: 0.4671 - val_loss: 1.5971 - val_accuracy: 0.4250 - lr: 7.8125e-06\n",
      "Epoch 69/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.4858 - accuracy: 0.4674 - val_loss: 1.5970 - val_accuracy: 0.4250 - lr: 7.8125e-06\n",
      "Epoch 70/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.4856 - accuracy: 0.4675 - val_loss: 1.5981 - val_accuracy: 0.4204 - lr: 7.8125e-06\n",
      "Epoch 71/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.4844 - accuracy: 0.4678 - val_loss: 1.5961 - val_accuracy: 0.4236 - lr: 3.9063e-06\n",
      "Epoch 72/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.4839 - accuracy: 0.4686 - val_loss: 1.5964 - val_accuracy: 0.4250 - lr: 3.9063e-06\n",
      "Epoch 73/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.4838 - accuracy: 0.4685 - val_loss: 1.5961 - val_accuracy: 0.4252 - lr: 3.9063e-06\n",
      "Epoch 74/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.4837 - accuracy: 0.4685 - val_loss: 1.5976 - val_accuracy: 0.4216 - lr: 3.9063e-06\n",
      "Epoch 75/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.4828 - accuracy: 0.4690 - val_loss: 1.5961 - val_accuracy: 0.4244 - lr: 1.9531e-06\n",
      "Epoch 76/200\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 1.4828 - accuracy: 0.4690 - val_loss: 1.5964 - val_accuracy: 0.4244 - lr: 1.9531e-06\n",
      "Epoch 77/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.4827 - accuracy: 0.4688 - val_loss: 1.5963 - val_accuracy: 0.4264 - lr: 1.9531e-06\n",
      "Epoch 78/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.4821 - accuracy: 0.4687 - val_loss: 1.5962 - val_accuracy: 0.4256 - lr: 9.7656e-07\n",
      "Epoch 79/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.4821 - accuracy: 0.4687 - val_loss: 1.5965 - val_accuracy: 0.4256 - lr: 9.7656e-07\n",
      "Epoch 80/200\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 1.4821 - accuracy: 0.4692 - val_loss: 1.5964 - val_accuracy: 0.4252 - lr: 9.7656e-07\n",
      "Epoch 81/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.4819 - accuracy: 0.4688 - val_loss: 1.5964 - val_accuracy: 0.4256 - lr: 4.8828e-07\n",
      "Epoch 82/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.4818 - accuracy: 0.4689 - val_loss: 1.5965 - val_accuracy: 0.4248 - lr: 4.8828e-07\n",
      "Epoch 83/200\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 1.4818 - accuracy: 0.4692 - val_loss: 1.5963 - val_accuracy: 0.4256 - lr: 4.8828e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a434c23b20>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_2.fit(X_train_nopca,y_train_nopca,batch_size=500,epochs=200,\n",
    "          callbacks=[mlp_2_tfboard,mlp_2_early,mlp_2_schedule],\n",
    "          validation_data=[X_valid_nopca,y_valid_nopca])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e73d30a2-e4e3-4d04-90a3-f73e42ee33f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 1.5838 - accuracy: 0.4331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5838027000427246, 0.43309998512268066]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_2.evaluate(X_test_raw,y_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b52b74-0e06-4c0e-be57-bd6e469cb6a0",
   "metadata": {},
   "source": [
    "It seems like my guessing was wrong. PCA actually gives better model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b70ca-68fa-4e10-bdce-2166f62a7e92",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9cc16e52-95b0-46a8-966c-d4ab7e2bfac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_keras_model(mlp_2,filename=\"mlp_2_nopca.h5\",save_weights=True,weights_precision='half')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068021b4-b5d9-4d0c-836a-a7cfa2a2e8d7",
   "metadata": {},
   "source": [
    "## MLP (20 x 100, SELU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d8d065-6e15-412d-9a53-4374ff6e2730",
   "metadata": {},
   "source": [
    "SELU activation requires the input to be scaled to mean 0 and std 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11689452-b89f-4101-8f53-d89ba9b18f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f964323-48f6-473d-8dc9-bbef5eea9dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_3 = keras.models.Sequential([keras.layers.Input((700,))])\n",
    "[mlp_3.add(layer) for layer in [\n",
    "    keras.layers.Dense(100,activation='selu',kernel_initializer='lecun_normal',)\n",
    "    for i in range(20)\n",
    "]]\n",
    "mlp_3.add(keras.layers.Dense(10,activation='softmax',kernel_initializer='lecun_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3407a74-9036-4353-b537-10c8caf896f1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 100)               70100     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 263,010\n",
      "Trainable params: 263,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4aa49f41-8a3f-44b0-ad29-5e9b79fcd535",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_3_logdir = get_tf_logdir(\"mlp_3\")\n",
    "mlp_3_tfboard = keras.callbacks.TensorBoard(mlp_3_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e64068de-fef2-4b10-aefb-903dcfd024b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_3_early = keras.callbacks.EarlyStopping(patience=10)\n",
    "mlp_3_opt = keras.optimizers.Nadam(learning_rate=0.001)\n",
    "mlp_3_schedule = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e7bb51b-de01-4dda-ab79-050db8ce7a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_3.compile(optimizer=mlp_3_opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60ebfaf5-7736-482b-9232-016b6fedeb20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 11s 62ms/step - loss: 2.2106 - accuracy: 0.1758 - val_loss: 1.9727 - val_accuracy: 0.2494 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 1.8694 - accuracy: 0.3046 - val_loss: 1.8423 - val_accuracy: 0.3220 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 1.7219 - accuracy: 0.3682 - val_loss: 1.7533 - val_accuracy: 0.3542 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 1.6186 - accuracy: 0.4161 - val_loss: 1.7217 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 1.5275 - accuracy: 0.4489 - val_loss: 1.7448 - val_accuracy: 0.3704 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 1.4379 - accuracy: 0.4810 - val_loss: 1.7143 - val_accuracy: 0.3922 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 1.3605 - accuracy: 0.5111 - val_loss: 1.7150 - val_accuracy: 0.4092 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 1.2931 - accuracy: 0.5364 - val_loss: 1.7614 - val_accuracy: 0.4026 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 1.2239 - accuracy: 0.5605 - val_loss: 1.7573 - val_accuracy: 0.4104 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 1.0398 - accuracy: 0.6295 - val_loss: 1.8149 - val_accuracy: 0.4168 - lr: 5.0000e-04\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.9462 - accuracy: 0.6645 - val_loss: 1.9003 - val_accuracy: 0.4164 - lr: 5.0000e-04\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.8864 - accuracy: 0.6868 - val_loss: 1.9865 - val_accuracy: 0.4190 - lr: 5.0000e-04\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.7647 - accuracy: 0.7336 - val_loss: 2.1122 - val_accuracy: 0.4192 - lr: 2.5000e-04\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.6975 - accuracy: 0.7620 - val_loss: 2.2306 - val_accuracy: 0.4106 - lr: 2.5000e-04\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.6529 - accuracy: 0.7787 - val_loss: 2.3361 - val_accuracy: 0.4096 - lr: 2.5000e-04\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.5798 - accuracy: 0.8098 - val_loss: 2.4564 - val_accuracy: 0.4126 - lr: 1.2500e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2909dc34760>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_3.fit(X_train_scaled,y_train,batch_size=500,epochs=200,\n",
    "          callbacks=[mlp_3_tfboard,mlp_3_early,mlp_3_schedule],\n",
    "          validation_data=[X_valid_scaled,y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "306f59b5-3564-41c0-8d20-3dd798b4089a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 2.4534 - accuracy: 0.4096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4533722400665283, 0.40959998965263367]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_3.evaluate(X_test_scaled,y_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02ca2f3-7f2f-499c-8317-739fdf7405ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb77d2e2-b08a-45dd-8431-9c8df19068e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_keras_model(mlp_3,filename=\"mlp_3_selu.h5\",save_weights=True,weights_precision='half')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65cec91-a46d-46cf-93e0-fafdb6d353ec",
   "metadata": {},
   "source": [
    "This model is not particularly useful, except that it converges faster than the one with batch normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9228c763-af1a-4acd-b5c4-ded53485916e",
   "metadata": {},
   "source": [
    "## MLP (20 x 100, Dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7710dab5-e500-4d04-b4e1-0f013f2bce7c",
   "metadata": {},
   "source": [
    "Since the first model mlp_0 performs the best while looking like its overfitting. We will try to apply Dropout regularization to the model mlp_0 and see if it improves the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad009c00-7549-4c5c-bbd1-6af1bd991606",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_4_dropout_rate = 0.05\n",
    "mlp_4 = keras.models.Sequential([\n",
    "    keras.layers.Input((700,))\n",
    "])\n",
    "mlp_4.add(keras.layers.Dropout(mlp_4_dropout_rate))\n",
    "[[mlp_4.add(keras.layers.Dense(100,activation='elu',kernel_initializer='he_normal')),\n",
    " mlp_4.add(keras.layers.Dropout(mlp_4_dropout_rate))] for i in range(20)]\n",
    "mlp_4.add(keras.layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc59703f-2cb7-4056-a9d3-afdf4e6d345c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout_106 (Dropout)       (None, 700)               0         \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 100)               70100     \n",
      "                                                                 \n",
      " dropout_107 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_110 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_111 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_114 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_115 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_116 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_117 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_120 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_121 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_122 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_123 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_124 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_125 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_126 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 263,010\n",
      "Trainable params: 263,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecbd0eb0-ca9e-4af1-944c-ebf9ce9019e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_4_logdir = get_tf_logdir(\"mlp_4\")\n",
    "mlp_4_tfboard = keras.callbacks.TensorBoard(mlp_4_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4b302ff-c5bf-423d-8a7f-f7097ab0ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_4_early = keras.callbacks.EarlyStopping(patience=10)\n",
    "mlp_4_opt = keras.optimizers.Nadam(learning_rate=0.001)\n",
    "mlp_4_schedule = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "552076a2-adc0-4572-a7b4-9a1d7c9cffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_4.compile(optimizer=mlp_4_opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "24936b1b-e1c4-4f7c-9628-778cebf251ce",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 9s 66ms/step - loss: 2.4694 - accuracy: 0.1548 - val_loss: 1.9698 - val_accuracy: 0.2588 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 2.0518 - accuracy: 0.2307 - val_loss: 1.8465 - val_accuracy: 0.3130 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 1.9508 - accuracy: 0.2718 - val_loss: 1.7886 - val_accuracy: 0.3426 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 1.8719 - accuracy: 0.3140 - val_loss: 1.7141 - val_accuracy: 0.3834 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.7939 - accuracy: 0.3500 - val_loss: 1.6488 - val_accuracy: 0.3996 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.7300 - accuracy: 0.3804 - val_loss: 1.5991 - val_accuracy: 0.4286 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 1.6826 - accuracy: 0.3971 - val_loss: 1.5725 - val_accuracy: 0.4382 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 1.6414 - accuracy: 0.4182 - val_loss: 1.5774 - val_accuracy: 0.4438 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.6089 - accuracy: 0.4304 - val_loss: 1.5194 - val_accuracy: 0.4602 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 1.5672 - accuracy: 0.4466 - val_loss: 1.5268 - val_accuracy: 0.4580 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.5496 - accuracy: 0.4535 - val_loss: 1.4855 - val_accuracy: 0.4666 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 1.5166 - accuracy: 0.4646 - val_loss: 1.4775 - val_accuracy: 0.4774 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 1.4935 - accuracy: 0.4781 - val_loss: 1.4766 - val_accuracy: 0.4718 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 1.4674 - accuracy: 0.4818 - val_loss: 1.4622 - val_accuracy: 0.4866 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 1.4456 - accuracy: 0.4904 - val_loss: 1.4553 - val_accuracy: 0.4860 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.4280 - accuracy: 0.4994 - val_loss: 1.4484 - val_accuracy: 0.4850 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 1.4072 - accuracy: 0.5092 - val_loss: 1.4509 - val_accuracy: 0.4918 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.3900 - accuracy: 0.5118 - val_loss: 1.4399 - val_accuracy: 0.4902 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 1.3770 - accuracy: 0.5205 - val_loss: 1.4370 - val_accuracy: 0.4934 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.3603 - accuracy: 0.5263 - val_loss: 1.4383 - val_accuracy: 0.4926 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.3371 - accuracy: 0.5322 - val_loss: 1.4412 - val_accuracy: 0.5046 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.3259 - accuracy: 0.5370 - val_loss: 1.4507 - val_accuracy: 0.4960 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 1.2931 - accuracy: 0.5500 - val_loss: 1.4221 - val_accuracy: 0.5014 - lr: 5.0000e-04\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.2774 - accuracy: 0.5536 - val_loss: 1.4237 - val_accuracy: 0.5012 - lr: 5.0000e-04\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 1.2670 - accuracy: 0.5566 - val_loss: 1.4212 - val_accuracy: 0.5030 - lr: 5.0000e-04\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 1.2549 - accuracy: 0.5603 - val_loss: 1.4211 - val_accuracy: 0.5058 - lr: 5.0000e-04\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 6s 61ms/step - loss: 1.2460 - accuracy: 0.5652 - val_loss: 1.4179 - val_accuracy: 0.5006 - lr: 5.0000e-04\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 1.2399 - accuracy: 0.5696 - val_loss: 1.4091 - val_accuracy: 0.5036 - lr: 5.0000e-04\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.2283 - accuracy: 0.5711 - val_loss: 1.4224 - val_accuracy: 0.5086 - lr: 5.0000e-04\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 1.2234 - accuracy: 0.5745 - val_loss: 1.4114 - val_accuracy: 0.5076 - lr: 5.0000e-04\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 1.2250 - accuracy: 0.5737 - val_loss: 1.4309 - val_accuracy: 0.5072 - lr: 5.0000e-04\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.1961 - accuracy: 0.5820 - val_loss: 1.4144 - val_accuracy: 0.5148 - lr: 2.5000e-04\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 1.1873 - accuracy: 0.5888 - val_loss: 1.4267 - val_accuracy: 0.5110 - lr: 2.5000e-04\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.1891 - accuracy: 0.5859 - val_loss: 1.4125 - val_accuracy: 0.5110 - lr: 2.5000e-04\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 1.1812 - accuracy: 0.5904 - val_loss: 1.4148 - val_accuracy: 0.5112 - lr: 1.2500e-04\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 1.1719 - accuracy: 0.5903 - val_loss: 1.4164 - val_accuracy: 0.5118 - lr: 1.2500e-04\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.1737 - accuracy: 0.5902 - val_loss: 1.4139 - val_accuracy: 0.5104 - lr: 1.2500e-04\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 1.1689 - accuracy: 0.5938 - val_loss: 1.4120 - val_accuracy: 0.5096 - lr: 6.2500e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x290a34d0190>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_4.fit(X_train,y_train,batch_size=500,epochs=200,\n",
    "          callbacks=[mlp_4_tfboard,mlp_4_early,mlp_4_schedule],\n",
    "          validation_data=[X_valid,y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "79c02247-6e39-4257-875f-a3ba453a2998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 1.3994 - accuracy: 0.5192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3993505239486694, 0.5192000269889832]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_4.evaluate(X_test_trans,y_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b793b09-bb13-44c4-91b3-dfc78cd4ab11",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "69bb11d7-c6c1-466f-8936-8c98666ab80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_keras_model(mlp_4,filename=\"mlp_4_dropout.h5\",save_weights=True,weights_precision='half')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16ef34e-33a6-4aaf-a10e-95fa20c2eebb",
   "metadata": {},
   "source": [
    "This model is not particularly useful, except that it converges faster than the one with batch normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58080f1-7742-4ccc-9ef6-e9c6de9dd0d6",
   "metadata": {},
   "source": [
    "After regularizing the exact same model as mlp_0 with dropout regularization, we get to increase the performance up to 0.5192.\\\n",
    "Although it sounds not very useful, but this approach is still better than the few other approaches tried in mlp_1 to mlp_3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e85b76f-5adb-41cd-951c-bbee6af51dda",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643e44f-8851-4f8c-817e-f76e719758bb",
   "metadata": {},
   "source": [
    "The best MLP model that I discovered so far for predicting CIFAR10 datasets is as follow:\n",
    "\n",
    "Model: Sequential (20 hidden layers with 100 neurons each)\\\n",
    "Activation: ELU\\\n",
    "Initialization: He Normal\\\n",
    "Regularization: Early Stopping, Dropout (rate = 0.05)\\\n",
    "Optimizer: Nadam\\\n",
    "Loss Function: Sparse Categorical Cross Entropy\\\n",
    "Learning Rate Schedule: Performance Scheduler (factor = 0.5, patience = 3)\\\n",
    "Output Activation: Softmax\n",
    "\n",
    "Evaluation Accuracy: 0.5192"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
