{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "608e6aa7-bb36-40c1-9537-e731c1dca9c4",
   "metadata": {},
   "source": [
    "# CIFAR10 MLP 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6303e19d-9e82-4580-b88f-dc279985fa2c",
   "metadata": {},
   "source": [
    "Due to the unsatisfied performance of the previous MLP model (0.5192 val_accuracy), let's try another MLP network model with lesser number of layers but also with more number of neurons per layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09597ba6-b89b-456d-96a5-25bdabd9f0e3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2d9768e-1f8c-4610-af06-f9d99c7556a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from mltoolkit.neural_networks import make_mlp\n",
    "from mltoolkit.utils import dump_keras_model,dump_arrays,dump_sklearn_model,\\\n",
    "                            get_tf_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "be8ecf2f-55df-44f7-a6d2-f9b4f31e0d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mlp(input_X,output_y,hidden_layers,neurons,\n",
    "             flatten=False,\n",
    "             hid_activation='relu',\n",
    "             hid_initializer='glorot_uniform',\n",
    "             hid_regularizer=None,\n",
    "             out_activation=None,\n",
    "             batch_norm=False,\n",
    "             dropout=False,\n",
    "             dropout_rate=0.2):\n",
    "    '''\n",
    "    Create a Sequential MLP model. All hidden layers will have the same\n",
    "    number of neurons, activation function, initializer and regularizer.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    input_X: nd-array\n",
    "        The input dataset X. Used to determine the shape of the input dataset.\n",
    "    output_y: 1d-array\n",
    "        The output dataset y. Used to determine the type and number of neurons\n",
    "        for the output layer.\n",
    "    hidden_layers: int\n",
    "        The number of hidden layers for the model.\n",
    "    neurons: int\n",
    "        The number of neurons for each hidden layer in the model.\n",
    "    flatten: bool, Default: False\n",
    "        Whether to flatten the input dataset X. If input_X is already\n",
    "        flatten, this should be False.\n",
    "    hid_activation: str, Default: 'relu\n",
    "        Activation function used for all the hidden layers.\n",
    "    hid_initializer: str, Default: 'glorot_uniform'\n",
    "        Initializer used for all the hidden layers.\n",
    "    hid_regularizer: str, Default: None\n",
    "        Regularizer used for all the hidden layers.\n",
    "    out_activation: str, Default: None\n",
    "        Activation function used for the output layer.\n",
    "        For regression model, this should be leave as None.\n",
    "        For classification model, this should be passed with the relevant\n",
    "        activation function e.g. 'softmax'.\n",
    "    batch_norm: bool, Default: False\n",
    "        Whether to include layers of batch normalization for each hidden layer.\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    keras.Sequential: \n",
    "    '''\n",
    "    if (batch_norm and dropout):\n",
    "        raise AssertionError(\"This function is for generating simple \" +\n",
    "                             \"MLP models, batch normalization and dropout \" +\n",
    "                             \"cannot be used together, please create the \" +\n",
    "                             \"model manually instead\")\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Input(shape=input_X.shape[1:])\n",
    "    ])\n",
    "    if flatten: model.add(keras.layers.Flatten())\n",
    "    if batch_norm:\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        [[model.add(layer),\n",
    "         model.add(keras.layers.BatchNormalization()),\n",
    "         model.add(keras.layers.Activation(hid_activation))] \n",
    "         for layer in [\n",
    "            keras.layers.Dense(neurons,\n",
    "                               kernel_initializer=hid_initializer,\n",
    "                               kernel_regularizer=hid_regularizer)\n",
    "            for i in range(hidden_layers)\n",
    "        ]]\n",
    "    elif dropout:\n",
    "        model.add(keras.layers.Dropout(dropout_rate))\n",
    "        [[model.add(layer),\n",
    "         model.add(keras.layers.Dropout(dropout_rate))] \n",
    "         for layer in [\n",
    "            keras.layers.Dense(neurons,\n",
    "                               activation=hid_activation,\n",
    "                               kernel_initializer=hid_initializer,\n",
    "                               kernel_regularizer=hid_regularizer)\n",
    "            for i in range(hidden_layers)\n",
    "        ]]\n",
    "    else:\n",
    "        [model.add(layer) for layer in [\n",
    "            keras.layers.Dense(neurons,\n",
    "                               activation=hid_activation,\n",
    "                               kernel_initializer=hid_initializer,\n",
    "                               kernel_regularizer=hid_regularizer)\n",
    "            for i in range(hidden_layers)\n",
    "        ]]\n",
    "        \n",
    "    \n",
    "    if output_y.dtype == int or output_y.dtype == float:\n",
    "        model.add(keras.layers.Dense(1,activation=None))\n",
    "    else:\n",
    "        model.add(keras.layers.Dense(np.unique(output_y).size,activation=out_activation))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06299a84-935a-46d6-a66f-25eddd1921f1",
   "metadata": {},
   "source": [
    "## Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5952264-c56e-4e0d-9abd-81fb4bc54980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 700), (10000, 700), (50000,), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trans = joblib.load(\"Datasets\\\\X_train_trans.pkl\")\n",
    "X_test_trans = joblib.load(\"Datasets\\\\X_test_trans.pkl\")\n",
    "y_train_raw = joblib.load(\"Datasets\\\\Raw Data\\\\y_train_raw.pkl\")\n",
    "y_test_raw = joblib.load(\"Datasets\\\\Raw Data\\\\y_test_raw.pkl\")\n",
    "\n",
    "X_train_trans.shape,X_test_trans.shape,y_train_raw.shape,y_test_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7d3579-5025-4e89-9deb-8e5c74fe1d8b",
   "metadata": {},
   "source": [
    "Note that the X_train and X_test are both PCA transformed with 700 components to reduce the dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb20ad92-2cf7-4d04-81bb-0900ed257631",
   "metadata": {},
   "source": [
    "## Splitting the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9456c96-cde5-48bd-9d0f-15586076dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_valid,y_train,y_valid = train_test_split(X_train_trans,y_train_raw,test_size=0.1,stratify=y_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716236d-fa1c-41ef-83eb-32afe6c36fcb",
   "metadata": {},
   "source": [
    "## MLP (5 x 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb56b040-29b2-4cb6-90ad-8f2f2928db9a",
   "metadata": {},
   "source": [
    "As usual, we will start with the vanilla model first. Then we only proceed to modify the model accordingly.\n",
    "\n",
    "mlp_5: Default MLP with 5 hidden layers and 400 neurons each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b189630c-23da-4f0f-b2b2-c9652f8b69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_5 = make_mlp(X_train,y_train,5,400,\n",
    "                 hid_activation='elu',out_activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92c1ed02-dd2d-4c1a-9fe2-c40632c3173d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 400)               280400    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 400)               160400    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 400)               160400    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 400)               160400    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 400)               160400    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                4010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 926,010\n",
      "Trainable params: 926,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8ba0136-02e1-4f80-bc2f-121afae807f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_5_logdir = get_tf_logdir(\"mlp_5\")\n",
    "mlp_5_tfboard = keras.callbacks.TensorBoard(mlp_5_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec490212-4956-401d-a445-5cb7c54eadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_5_monitor = 'val_accuracy'\n",
    "mlp_5_early = keras.callbacks.EarlyStopping(monitor=mlp_5_monitor,patience=10,restore_best_weights=True)\n",
    "mlp_5_opt = keras.optimizers.Nadam(learning_rate=0.001)\n",
    "mlp_5_schedule = keras.callbacks.ReduceLROnPlateau(monitor=mlp_5_monitor,factor=0.5,patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5797001-15ed-46b8-b3cb-c3ede4ec143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_5.compile(optimizer=mlp_5_opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bd762f7-d47d-479d-8c0d-4cf6d98f99f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 3s 19ms/step - loss: 1.7064 - accuracy: 0.3941 - val_loss: 1.5366 - val_accuracy: 0.4546 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 1.4275 - accuracy: 0.4932 - val_loss: 1.4392 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 1.2820 - accuracy: 0.5439 - val_loss: 1.3984 - val_accuracy: 0.5062 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 1.1697 - accuracy: 0.5842 - val_loss: 1.3879 - val_accuracy: 0.5132 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 1.0728 - accuracy: 0.6187 - val_loss: 1.4035 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 1s 17ms/step - loss: 0.9732 - accuracy: 0.6527 - val_loss: 1.4144 - val_accuracy: 0.5326 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.8793 - accuracy: 0.6878 - val_loss: 1.4440 - val_accuracy: 0.5268 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.7810 - accuracy: 0.7209 - val_loss: 1.5126 - val_accuracy: 0.5268 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.6780 - accuracy: 0.7593 - val_loss: 1.6196 - val_accuracy: 0.5140 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.4622 - accuracy: 0.8463 - val_loss: 1.6597 - val_accuracy: 0.5388 - lr: 5.0000e-04\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.3756 - accuracy: 0.8803 - val_loss: 1.7845 - val_accuracy: 0.5362 - lr: 5.0000e-04\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 0.3086 - accuracy: 0.9034 - val_loss: 1.9522 - val_accuracy: 0.5338 - lr: 5.0000e-04\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.2505 - accuracy: 0.9238 - val_loss: 2.0890 - val_accuracy: 0.5280 - lr: 5.0000e-04\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.1629 - accuracy: 0.9618 - val_loss: 2.1697 - val_accuracy: 0.5336 - lr: 2.5000e-04\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.1290 - accuracy: 0.9736 - val_loss: 2.2692 - val_accuracy: 0.5376 - lr: 2.5000e-04\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.1076 - accuracy: 0.9803 - val_loss: 2.3852 - val_accuracy: 0.5324 - lr: 2.5000e-04\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0809 - accuracy: 0.9894 - val_loss: 2.4453 - val_accuracy: 0.5366 - lr: 1.2500e-04\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0717 - accuracy: 0.9917 - val_loss: 2.5163 - val_accuracy: 0.5324 - lr: 1.2500e-04\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0643 - accuracy: 0.9932 - val_loss: 2.5804 - val_accuracy: 0.5320 - lr: 1.2500e-04\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0551 - accuracy: 0.9953 - val_loss: 2.6107 - val_accuracy: 0.5320 - lr: 6.2500e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x263c1e15930>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_5.fit(X_train,y_train,batch_size=500,epochs=200,\n",
    "          callbacks=[mlp_5_tfboard,mlp_5_early,mlp_5_schedule],\n",
    "          validation_data=[X_valid,y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "544be21f-f97d-4d91-9cd7-dffa115282e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 1.6257 - accuracy: 0.5387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6256675720214844, 0.5386999845504761]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_5.evaluate(X_test_trans,y_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8981994-2006-4a49-8a8a-f6871f18a782",
   "metadata": {},
   "source": [
    "This model now works even better than the one in the previous try with (20 x 100) architecture.\\\n",
    "The model also is now seriously overfitting the input training dataset which means our model architecture is able to hold most of the information possessed by our data.\n",
    "\n",
    "We will try to regularize the model and see if it actually improves the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288a4952-feaa-479b-a0f9-57e9bd598708",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ca33acf-36f5-4899-a5da-5b2798c84555",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_keras_model(mlp_5,filename=\"mlp_5.h5\",save_weights=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d670a3-3915-4857-b2e1-fb72cf51abeb",
   "metadata": {},
   "source": [
    "## MLP (5 x 400, L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc0f1de-4729-45f6-861a-8fc7cd59a1df",
   "metadata": {},
   "source": [
    "Let's try with the simplest L1 regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "15c8bcb9-1688-4760-9efa-774827858ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_6_regular = keras.regularizers.L1(l1=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "94d56b59-2d6f-43bd-93cb-2873742fe1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_6 = make_mlp(X_train,y_train,5,400,\n",
    "                 hid_activation='elu',hid_regularizer=mlp_6_regular,out_activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a0618cd3-3872-42ec-b2d1-2c3dc96b1b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 400)               280400    \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 400)               160400    \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 400)               160400    \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 400)               160400    \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 400)               160400    \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 10)                4010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 926,010\n",
      "Trainable params: 926,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f92571cb-1948-45df-8b72-fb7086430c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_6_logdir = get_tf_logdir(\"mlp_6\")\n",
    "mlp_6_tfboard = keras.callbacks.TensorBoard(mlp_6_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "94155e4f-f674-48de-bb25-f0e41991a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_6_monitor = 'val_accuracy'\n",
    "mlp_6_early = keras.callbacks.EarlyStopping(monitor=mlp_6_monitor,patience=10,restore_best_weights=True)\n",
    "mlp_6_opt = keras.optimizers.Nadam(learning_rate=0.005)\n",
    "mlp_6_schedule = keras.callbacks.ReduceLROnPlateau(monitor=mlp_6_monitor,factor=0.5,patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ba6f1ee9-8453-4416-b437-c899b3ff25a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_6.compile(optimizer=mlp_6_opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "30ba8ad2-7a3f-4684-9176-2dfdcc53ffde",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 3s 22ms/step - loss: 4.8302 - accuracy: 0.3661 - val_loss: 3.7834 - val_accuracy: 0.4048 - lr: 0.0050\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 3.2319 - accuracy: 0.4301 - val_loss: 2.7949 - val_accuracy: 0.4314 - lr: 0.0050\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 2.4452 - accuracy: 0.4524 - val_loss: 2.2029 - val_accuracy: 0.4610 - lr: 0.0050\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 2.0191 - accuracy: 0.4762 - val_loss: 1.9559 - val_accuracy: 0.4628 - lr: 0.0050\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.8220 - accuracy: 0.4928 - val_loss: 1.8172 - val_accuracy: 0.4776 - lr: 0.0050\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.7095 - accuracy: 0.5138 - val_loss: 1.7598 - val_accuracy: 0.4826 - lr: 0.0050\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.6461 - accuracy: 0.5294 - val_loss: 1.7138 - val_accuracy: 0.5044 - lr: 0.0050\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.5994 - accuracy: 0.5423 - val_loss: 1.6851 - val_accuracy: 0.5116 - lr: 0.0050\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.5613 - accuracy: 0.5547 - val_loss: 1.6773 - val_accuracy: 0.5184 - lr: 0.0050\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.5332 - accuracy: 0.5656 - val_loss: 1.6586 - val_accuracy: 0.5234 - lr: 0.0050\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.5057 - accuracy: 0.5767 - val_loss: 1.6444 - val_accuracy: 0.5218 - lr: 0.0050\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.4905 - accuracy: 0.5831 - val_loss: 1.6528 - val_accuracy: 0.5248 - lr: 0.0050\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.4701 - accuracy: 0.5873 - val_loss: 1.6361 - val_accuracy: 0.5332 - lr: 0.0050\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.4539 - accuracy: 0.5962 - val_loss: 1.6488 - val_accuracy: 0.5390 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.4378 - accuracy: 0.6043 - val_loss: 1.6540 - val_accuracy: 0.5340 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.4288 - accuracy: 0.6084 - val_loss: 1.6722 - val_accuracy: 0.5320 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.4172 - accuracy: 0.6165 - val_loss: 1.6912 - val_accuracy: 0.5286 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.2951 - accuracy: 0.6493 - val_loss: 1.6185 - val_accuracy: 0.5472 - lr: 0.0025\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.2703 - accuracy: 0.6555 - val_loss: 1.6309 - val_accuracy: 0.5508 - lr: 0.0025\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.2620 - accuracy: 0.6610 - val_loss: 1.6478 - val_accuracy: 0.5504 - lr: 0.0025\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.2558 - accuracy: 0.6629 - val_loss: 1.6491 - val_accuracy: 0.5488 - lr: 0.0025\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.2466 - accuracy: 0.6676 - val_loss: 1.6803 - val_accuracy: 0.5472 - lr: 0.0025\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.1665 - accuracy: 0.6927 - val_loss: 1.6613 - val_accuracy: 0.5536 - lr: 0.0012\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 1.1494 - accuracy: 0.6971 - val_loss: 1.6782 - val_accuracy: 0.5560 - lr: 0.0012\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.1414 - accuracy: 0.7025 - val_loss: 1.7068 - val_accuracy: 0.5544 - lr: 0.0012\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.1346 - accuracy: 0.7042 - val_loss: 1.7169 - val_accuracy: 0.5546 - lr: 0.0012\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.1281 - accuracy: 0.7100 - val_loss: 1.7425 - val_accuracy: 0.5500 - lr: 0.0012\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.0773 - accuracy: 0.7266 - val_loss: 1.7340 - val_accuracy: 0.5482 - lr: 6.2500e-04\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.0667 - accuracy: 0.7289 - val_loss: 1.7603 - val_accuracy: 0.5510 - lr: 6.2500e-04\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.0621 - accuracy: 0.7319 - val_loss: 1.7733 - val_accuracy: 0.5494 - lr: 6.2500e-04\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.0333 - accuracy: 0.7420 - val_loss: 1.7721 - val_accuracy: 0.5514 - lr: 3.1250e-04\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.0281 - accuracy: 0.7435 - val_loss: 1.7854 - val_accuracy: 0.5466 - lr: 3.1250e-04\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.0249 - accuracy: 0.7456 - val_loss: 1.7975 - val_accuracy: 0.5486 - lr: 3.1250e-04\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.0096 - accuracy: 0.7503 - val_loss: 1.7966 - val_accuracy: 0.5480 - lr: 1.5625e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x263eae13dc0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_6.fit(X_train,y_train,batch_size=500,epochs=200,\n",
    "          callbacks=[mlp_6_tfboard,mlp_6_early,mlp_6_schedule],\n",
    "          validation_data=[X_valid,y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1a0ad735-4992-447e-8f99-2d1345ad7c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 1.6550 - accuracy: 0.5511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.654964804649353, 0.5511000156402588]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_6.evaluate(X_test_trans,y_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c3a866-2b1f-4a46-97fa-1df14f17895a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "eaf39d7a-e0a8-4af5-9092-a9358fdf01f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_keras_model(mlp_6,filename=\"mlp_6.h5\",save_weights=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ace77b-349b-493a-9d15-ffb7aff4b92a",
   "metadata": {},
   "source": [
    "Now the evaluation accuracy is up to 0.5511.\\\n",
    "But the model is still slightly overfitting.\n",
    "\n",
    "We will try adding Dropout regularizer next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b1a694-1022-4d2a-af7c-8b3e077813b6",
   "metadata": {},
   "source": [
    "## MLP (5 x 400, L1, Dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e49b9-669e-4daf-8902-20de573d044e",
   "metadata": {},
   "source": [
    "Let's try with the simplest L1 regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2d6ba66b-c26c-43d9-a9ed-1528ab5700a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_7_regular = keras.regularizers.L1(l1=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8f66a9b3-2678-48c4-913e-71105c2a8f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_7 = make_mlp(X_train,y_train,5,400,\n",
    "                 hid_activation='elu',\n",
    "                 hid_regularizer=mlp_7_regular,\n",
    "                 out_activation='softmax',\n",
    "                 dropout=True,dropout_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "27ed6256-8cd7-4349-8e3c-09415736bb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout_6 (Dropout)         (None, 700)               0         \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 400)               280400    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 400)               160400    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 400)               160400    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 400)               160400    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 400)               0         \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 400)               160400    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 400)               0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 10)                4010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 926,010\n",
      "Trainable params: 926,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ff69d80c-15d3-4b05-a07c-93394eba6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_7_logdir = get_tf_logdir(\"mlp_7\")\n",
    "mlp_7_tfboard = keras.callbacks.TensorBoard(mlp_7_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d2c23813-0960-499a-a4f5-1a35e205b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_7_monitor = 'val_accuracy'\n",
    "mlp_7_early = keras.callbacks.EarlyStopping(monitor=mlp_7_monitor,patience=10,restore_best_weights=True)\n",
    "mlp_7_opt = keras.optimizers.Nadam(learning_rate=0.005)\n",
    "mlp_7_schedule = keras.callbacks.ReduceLROnPlateau(monitor=mlp_7_monitor,factor=0.5,patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e760e53e-698c-4828-adec-617b4ac1ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_7.compile(optimizer=mlp_7_opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0ea409f1-c85a-43f3-95da-59a359093803",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 3s 22ms/step - loss: 4.7864 - accuracy: 0.3215 - val_loss: 3.6078 - val_accuracy: 0.3818 - lr: 0.0050\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 3.0678 - accuracy: 0.3797 - val_loss: 2.4917 - val_accuracy: 0.4166 - lr: 0.0050\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 2.3142 - accuracy: 0.3955 - val_loss: 2.0464 - val_accuracy: 0.4220 - lr: 0.0050\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 2.0343 - accuracy: 0.4128 - val_loss: 1.8602 - val_accuracy: 0.4590 - lr: 0.0050\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.9227 - accuracy: 0.4283 - val_loss: 1.7779 - val_accuracy: 0.4718 - lr: 0.0050\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.8733 - accuracy: 0.4418 - val_loss: 1.7445 - val_accuracy: 0.4744 - lr: 0.0050\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.8351 - accuracy: 0.4506 - val_loss: 1.7131 - val_accuracy: 0.4852 - lr: 0.0050\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.8132 - accuracy: 0.4576 - val_loss: 1.6910 - val_accuracy: 0.4920 - lr: 0.0050\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.7926 - accuracy: 0.4659 - val_loss: 1.6954 - val_accuracy: 0.4916 - lr: 0.0050\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.7820 - accuracy: 0.4704 - val_loss: 1.6653 - val_accuracy: 0.5066 - lr: 0.0050\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.7670 - accuracy: 0.4748 - val_loss: 1.6748 - val_accuracy: 0.5084 - lr: 0.0050\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.7604 - accuracy: 0.4778 - val_loss: 1.6604 - val_accuracy: 0.5080 - lr: 0.0050\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.7416 - accuracy: 0.4842 - val_loss: 1.6579 - val_accuracy: 0.5158 - lr: 0.0050\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.7392 - accuracy: 0.4872 - val_loss: 1.6358 - val_accuracy: 0.5226 - lr: 0.0050\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.7314 - accuracy: 0.4894 - val_loss: 1.6434 - val_accuracy: 0.5114 - lr: 0.0050\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.7234 - accuracy: 0.4932 - val_loss: 1.6376 - val_accuracy: 0.5208 - lr: 0.0050\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.7243 - accuracy: 0.4980 - val_loss: 1.6385 - val_accuracy: 0.5214 - lr: 0.0050\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.6334 - accuracy: 0.5119 - val_loss: 1.5387 - val_accuracy: 0.5410 - lr: 0.0025\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.6145 - accuracy: 0.5183 - val_loss: 1.5406 - val_accuracy: 0.5402 - lr: 0.0025\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.6106 - accuracy: 0.5176 - val_loss: 1.5337 - val_accuracy: 0.5342 - lr: 0.0025\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.6070 - accuracy: 0.5175 - val_loss: 1.5366 - val_accuracy: 0.5390 - lr: 0.0025\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.5631 - accuracy: 0.5267 - val_loss: 1.4915 - val_accuracy: 0.5466 - lr: 0.0012\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.5507 - accuracy: 0.5282 - val_loss: 1.4850 - val_accuracy: 0.5434 - lr: 0.0012\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.5473 - accuracy: 0.5295 - val_loss: 1.4774 - val_accuracy: 0.5436 - lr: 0.0012\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.5419 - accuracy: 0.5312 - val_loss: 1.4791 - val_accuracy: 0.5418 - lr: 0.0012\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.5198 - accuracy: 0.5345 - val_loss: 1.4544 - val_accuracy: 0.5476 - lr: 6.2500e-04\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.5178 - accuracy: 0.5350 - val_loss: 1.4536 - val_accuracy: 0.5478 - lr: 6.2500e-04\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.5117 - accuracy: 0.5357 - val_loss: 1.4521 - val_accuracy: 0.5440 - lr: 6.2500e-04\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.5095 - accuracy: 0.5364 - val_loss: 1.4513 - val_accuracy: 0.5538 - lr: 6.2500e-04\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.5092 - accuracy: 0.5371 - val_loss: 1.4477 - val_accuracy: 0.5516 - lr: 6.2500e-04\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.5063 - accuracy: 0.5390 - val_loss: 1.4442 - val_accuracy: 0.5556 - lr: 6.2500e-04\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.5082 - accuracy: 0.5349 - val_loss: 1.4454 - val_accuracy: 0.5524 - lr: 6.2500e-04\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.5069 - accuracy: 0.5380 - val_loss: 1.4449 - val_accuracy: 0.5554 - lr: 6.2500e-04\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.5115 - accuracy: 0.5310 - val_loss: 1.4483 - val_accuracy: 0.5536 - lr: 6.2500e-04\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.4965 - accuracy: 0.5371 - val_loss: 1.4336 - val_accuracy: 0.5552 - lr: 3.1250e-04\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.4920 - accuracy: 0.5412 - val_loss: 1.4329 - val_accuracy: 0.5534 - lr: 3.1250e-04\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.4916 - accuracy: 0.5401 - val_loss: 1.4337 - val_accuracy: 0.5510 - lr: 3.1250e-04\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.4806 - accuracy: 0.5417 - val_loss: 1.4260 - val_accuracy: 0.5510 - lr: 1.5625e-04\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.4846 - accuracy: 0.5400 - val_loss: 1.4260 - val_accuracy: 0.5548 - lr: 1.5625e-04\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 1.4827 - accuracy: 0.5394 - val_loss: 1.4253 - val_accuracy: 0.5538 - lr: 1.5625e-04\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 1.4779 - accuracy: 0.5416 - val_loss: 1.4217 - val_accuracy: 0.5544 - lr: 7.8125e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x263bba15810>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_7.fit(X_train,y_train,batch_size=500,epochs=200,\n",
    "          callbacks=[mlp_7_tfboard,mlp_7_early,mlp_7_schedule],\n",
    "          validation_data=[X_valid,y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e044cc77-e8f8-45e1-b71c-e522c4479b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 1.4154 - accuracy: 0.5680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4153943061828613, 0.5680000185966492]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_7.evaluate(X_test_trans,y_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac3300-0d51-4dee-90c4-e352bdeb04ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ad63c1d3-70dd-42a3-b27c-c6e5cb81979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_keras_model(mlp_7,filename=\"mlp_7.h5\",save_weights=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89436e9-f4d7-46da-805e-7de9fc0530da",
   "metadata": {},
   "source": [
    "Now the evaluation accuracy is up to 0.5680.\\\n",
    "It did not improve by a whole lot, but regularization does help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc7b7d4-910a-4ea4-ae70-eea27bec8465",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e52f49-7c20-4e21-9960-30e4da5e8b87",
   "metadata": {},
   "source": [
    "Perhaps we should try other neural networks architectures in the future, it seems like this is pretty much what we can try for now.\n",
    "\n",
    "Model: Sequential (5 hidden layers with 400 neurons each)\\\n",
    "Activation: ELU\\\n",
    "Initialization: Glorot Uniform\\\n",
    "Regularization: Early Stopping, L1 (a = 0.0001) Dropout (rate = 0.1)\\\n",
    "Optimizer: Nadam\\\n",
    "Loss Function: Sparse Categorical Cross Entropy\\\n",
    "Learning Rate Schedule: Performance Scheduler (factor = 0.5, patience = 3)\\\n",
    "Output Activation: Softmax\n",
    "\n",
    "Evaluation Accuracy: 0.5680"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
